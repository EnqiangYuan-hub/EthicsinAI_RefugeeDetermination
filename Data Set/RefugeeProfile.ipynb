{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EnqiangYuan-hub/EthicsinAI_RefugeeDetermination/blob/main/Data%20Set/RefugeeProfile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RZ1Oq8sZI758"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Synthetic RSD Dataset Generator\n",
        "# Refugee Status Determination AI Case Study\n",
        "# ============================================================\n",
        "#\n",
        "# DESIGN NOTES:\n",
        "# This dataset intentionally encodes several known biases found in\n",
        "# real automated RSD systems:\n",
        "#\n",
        "#   1. CREDIBILITY BIAS: Credibility scores are partly driven by\n",
        "#      language proficiency and education. This reflects a documented\n",
        "#      flaw in real systems — formal expression is rewarded, even though\n",
        "#      trauma, culture, and circumstance affect how people communicate.\n",
        "#      (Kinchin & Mougouei, 2022; Kasapoglu et al., 2021)\n",
        "#\n",
        "#   2. TRAUMA PENALTY: Applicants with reported trauma have slightly\n",
        "#      lower credibility scores, mimicking how inconsistent or fragmented\n",
        "#      testimony (a common trauma response) is penalized in assessments.\n",
        "#\n",
        "#   3. COUNTRY-OF-ORIGIN BIAS: Risk scores vary by country, reflecting\n",
        "#      both real conflict data AND the way COI can encode systemic assumptions.\n",
        "#\n",
        "#   4. AUTOMATION BIAS: The human override rate is low (10%), and overrides\n",
        "#      only partially correct AI errors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# ============================================================\n",
        "# PART 1 — APPLICANT INPUTS\n",
        "# ============================================================\n",
        "\n",
        "n = 500\n",
        "\n",
        "countries = [\"Syria\", \"Afghanistan\", \"Sudan\", \"Myanmar\", \"Eritrea\", \"Venezuela\", \"Iraq\", \"Somalia\"]\n",
        "genders = [\"Male\", \"Female\", \"Non-binary\"]\n",
        "education_levels = [\"None\", \"Primary\", \"Secondary\", \"Tertiary\"]\n",
        "language_levels = [\"None\", \"Basic\", \"Intermediate\", \"Advanced\", \"Fluent\"]\n",
        "persecution_grounds = [\"race\", \"religion\", \"nationality\", \"political_opinion\", \"social_group\"]\n",
        "persecution_types = [\"violence\", \"detention\", \"threats\", \"sexual_violence\", \"discrimination\"]\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"id\": range(1, n + 1),\n",
        "    \"country_of_origin\": np.random.choice(countries, n),\n",
        "    # Gender sampling reflects approximate real-world RSD demographics.\n",
        "    # Non-binary/gender-nonconforming claimants are a small but recognized\n",
        "    # population under the 1951 Convention's \"particular social group\" ground.\n",
        "    # Set to ~4% to mirror real caseload proportions — this intentionally\n",
        "    # surfaces the underrepresentation problem in algorithmic audits.\n",
        "    \"gender\": np.random.choice(genders, n, p=[0.48, 0.48, 0.04]),\n",
        "    \"age\": np.random.randint(18, 65, n),\n",
        "    \"education_level\": np.random.choice(education_levels, n, p=[0.1, 0.3, 0.4, 0.2]),\n",
        "    \"language_proficiency\": np.random.choice(language_levels, n, p=[0.05, 0.25, 0.4, 0.2, 0.1]),\n",
        "    \"family_size\": np.random.randint(1, 7, n),\n",
        "    \"prior_camp_years\": np.random.randint(0, 10, n),\n",
        "    \"persecution_ground\": np.random.choice(persecution_grounds, n),\n",
        "    \"persecution_type\": np.random.choice(persecution_types, n),\n",
        "})\n",
        "\n",
        "df[\"nexus_established\"] = np.random.choice([True, False], n, p=[0.7, 0.3])\n",
        "\n",
        "# State protection: floor at 0.05 to avoid artifactual exact-zero values\n",
        "df[\"state_protection_score\"] = np.clip(np.random.normal(0.3, 0.15, n), 0.05, 1.0)\n",
        "\n",
        "df[\"internal_relocation_possible\"] = np.random.choice([True, False], n, p=[0.4, 0.6])\n",
        "\n",
        "# Trauma indicator — reflects literature showing trauma affects testimony quality\n",
        "# Higher rates for conflict-heavy regions and gendered persecution types\n",
        "trauma_base = np.where(\n",
        "    df[\"country_of_origin\"].isin([\"Syria\", \"Afghanistan\", \"Eritrea\", \"Somalia\"]), 0.65, 0.40\n",
        ")\n",
        "trauma_base = np.where(\n",
        "    df[\"persecution_type\"].isin([\"sexual_violence\", \"detention\"]),\n",
        "    np.minimum(trauma_base + 0.15, 0.85),\n",
        "    trauma_base\n",
        ")\n",
        "df[\"reported_trauma\"] = np.random.binomial(1, trauma_base).astype(bool)"
      ],
      "metadata": {
        "id": "8VITrPkxKXJ0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PART 2 — SCORING FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "# --- Credibility Score ---\n",
        "# Intentional bias: language and education inflate credibility.\n",
        "# Trauma REDUCES credibility slightly — reflecting how fragmented or\n",
        "# inconsistent trauma-affected testimony is penalized in real systems.\n",
        "# This is a documented flaw, not a correct design choice.\n",
        "\n",
        "language_map = {\"None\": -0.20, \"Basic\": -0.10, \"Intermediate\": 0.0, \"Advanced\": +0.05, \"Fluent\": +0.10}\n",
        "edu_map      = {\"None\": -0.10, \"Primary\": 0.0,  \"Secondary\": +0.05, \"Tertiary\": +0.10}\n",
        "\n",
        "base_cred    = np.random.normal(0.65, 0.15, n)\n",
        "lang_effect  = df[\"language_proficiency\"].map(language_map).values\n",
        "edu_effect   = df[\"education_level\"].map(edu_map).values\n",
        "trauma_penalty = np.where(df[\"reported_trauma\"], -0.08, 0.0)   # <-- intentional bias\n",
        "\n",
        "df[\"credibility_score\"] = np.clip(base_cred + lang_effect + edu_effect + trauma_penalty, 0.0, 1.0)\n",
        "\n",
        "# --- Risk Score ---\n",
        "# NOT capped at 1.0 before normalization — avoids invisible data artifacts.\n",
        "# Represents severity of persecution risk in country of origin.\n",
        "\n",
        "risk_means = {\n",
        "    \"Syria\": 0.85, \"Afghanistan\": 0.80, \"Sudan\": 0.75, \"Myanmar\": 0.70,\n",
        "    \"Eritrea\": 0.70, \"Venezuela\": 0.55, \"Iraq\": 0.65, \"Somalia\": 0.78\n",
        "}\n",
        "ptype_map = {\n",
        "    \"violence\": +0.10, \"detention\": +0.05, \"threats\": 0.0,\n",
        "    \"sexual_violence\": +0.15, \"discrimination\": -0.05\n",
        "}\n",
        "gender_map = {\"Male\": 0.0, \"Female\": +0.08, \"Non-binary\": +0.06}\n",
        "\n",
        "base_risk      = df[\"country_of_origin\"].map(risk_means).values\n",
        "ptype_effect   = df[\"persecution_type\"].map(ptype_map).values\n",
        "gender_effect  = df[\"gender\"].map(gender_map).values\n",
        "noise          = np.random.normal(0, 0.05, n)\n",
        "\n",
        "# Allow scores above 1.0 before clipping so the cap is visible/documented\n",
        "raw_risk = base_risk + ptype_effect + gender_effect + noise\n",
        "df[\"risk_score\"] = np.clip(raw_risk, 0.0, 1.0)\n",
        "df[\"risk_score_uncapped\"] = raw_risk  # kept for transparency; students can examine capping effects\n"
      ],
      "metadata": {
        "id": "DxEPS7iVKfMZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PART 3 — AI DECISION LOGIC\n",
        "# ============================================================\n",
        "# Threshold rule: approve if risk is high (real danger exists) AND\n",
        "# credibility clears a minimum bar. Nexus and state protection also factor in.\n",
        "# This produces a ~55-60% approval rate, closer to real-world figures.\n",
        "\n",
        "approve_score = (\n",
        "    0.45 * df[\"risk_score\"]\n",
        "    + 0.30 * df[\"credibility_score\"]\n",
        "    + 0.15 * df[\"nexus_established\"].astype(float)\n",
        "    + 0.10 * (1 - df[\"state_protection_score\"])\n",
        ")\n",
        "\n",
        "# Threshold tuned to produce ~55-60% approval rate.\n",
        "# risk_score is high for most conflict countries, so we require nexus AND\n",
        "# credibility to both clear reasonable bars to avoid near-universal approval.\n",
        "df[\"AI_decision\"] = np.where(\n",
        "    (approve_score > 0.62)\n",
        "    & (df[\"credibility_score\"] > 0.50)\n",
        "    & (df[\"nexus_established\"] == True),\n",
        "    \"approve\",\n",
        "    \"deny\"\n",
        ")"
      ],
      "metadata": {
        "id": "MRlTnHHgKi-F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PART 4 — HUMAN-IN-THE-LOOP OVERSIGHT\n",
        "# ============================================================\n",
        "# ~10% of cases flagged for human review.\n",
        "# Of reviewed cases, ~50% result in a flipped decision (human override).\n",
        "# This is intentionally low — reflects automation bias literature\n",
        "# where human reviewers tend to defer to the algorithm.\n",
        "\n",
        "df[\"human_reviewed\"] = False\n",
        "df[\"human_override\"] = False\n",
        "\n",
        "reviewed_idx = np.random.choice(df.index, size=int(0.10 * n), replace=False)\n",
        "df.loc[reviewed_idx, \"human_reviewed\"] = True\n",
        "\n",
        "# Of reviewed cases, flip ~50%\n",
        "flip_mask = (df[\"human_reviewed\"]) & (np.random.rand(n) < 0.50)\n",
        "df.loc[flip_mask, \"human_override\"] = True\n",
        "\n",
        "# Build final_decision: start from AI, apply flips where overridden\n",
        "df[\"final_decision\"] = df[\"AI_decision\"].copy()\n",
        "flip_idx = df[df[\"human_override\"]].index\n",
        "df.loc[flip_idx, \"final_decision\"] = df.loc[flip_idx, \"AI_decision\"].apply(\n",
        "    lambda x: \"deny\" if x == \"approve\" else \"approve\"\n",
        ")\n",
        "\n",
        "# Processing time: base 30-120 days, +20-60 if human reviewed\n",
        "base_time = np.random.randint(30, 120, n)\n",
        "review_delay = np.where(df[\"human_reviewed\"], np.random.randint(20, 60, n), 0)\n",
        "df[\"processing_time_days\"] = base_time + review_delay"
      ],
      "metadata": {
        "id": "g3kDuVnRK28e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PART 5 — APPEALS & BIAS AUDIT\n",
        "# ============================================================\n",
        "\n",
        "# 30% of denied applicants appeal\n",
        "appeal_rand = np.random.rand(n)\n",
        "df[\"appealed\"] = (df[\"final_decision\"] == \"deny\") & (appeal_rand < 0.30)\n",
        "\n",
        "# 40% of appeals are overturned\n",
        "appeal_outcomes = []\n",
        "for _, row in df.iterrows():\n",
        "    if not row[\"appealed\"]:\n",
        "        appeal_outcomes.append(\"N/A\")\n",
        "    elif np.random.rand() < 0.40:\n",
        "        appeal_outcomes.append(\"overturned\")\n",
        "    else:\n",
        "        appeal_outcomes.append(\"upheld\")\n",
        "df[\"appeal_outcome\"] = appeal_outcomes\n",
        "\n",
        "# Bias flag — simulate a fairness audit\n",
        "# Bias is more likely when trauma was present but credibility was low,\n",
        "# or when nexus was established but case was still denied.\n",
        "bias_probs = []\n",
        "for _, row in df.iterrows():\n",
        "    if row[\"reported_trauma\"] and row[\"credibility_score\"] < 0.5:\n",
        "        bias_probs.append(np.random.choice([\"none\", \"moderate\", \"severe\"], p=[0.40, 0.40, 0.20]))\n",
        "    elif row[\"nexus_established\"] and row[\"final_decision\"] == \"deny\":\n",
        "        bias_probs.append(np.random.choice([\"none\", \"moderate\", \"severe\"], p=[0.50, 0.35, 0.15]))\n",
        "    else:\n",
        "        bias_probs.append(np.random.choice([\"none\", \"moderate\", \"severe\"], p=[0.80, 0.15, 0.05]))\n",
        "df[\"bias_flag\"] = bias_probs"
      ],
      "metadata": {
        "id": "4gqDYqCOK81j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PART 6 — COLUMN ORDER & EXPORT\n",
        "# ============================================================\n",
        "\n",
        "column_order = [\n",
        "    # Applicant inputs\n",
        "    \"id\", \"country_of_origin\", \"gender\", \"age\",\n",
        "    \"education_level\", \"language_proficiency\",\n",
        "    \"family_size\", \"prior_camp_years\",\n",
        "    \"persecution_ground\", \"persecution_type\",\n",
        "    \"nexus_established\", \"state_protection_score\",\n",
        "    \"internal_relocation_possible\", \"reported_trauma\",\n",
        "    # Scores\n",
        "    \"credibility_score\", \"risk_score\", \"risk_score_uncapped\",\n",
        "    # System process\n",
        "    \"AI_decision\", \"human_reviewed\", \"human_override\",\n",
        "    \"final_decision\", \"processing_time_days\",\n",
        "    # Outcomes\n",
        "    \"appealed\", \"appeal_outcome\", \"bias_flag\"\n",
        "]\n",
        "\n",
        "df = df[column_order]"
      ],
      "metadata": {
        "id": "zqkJBfJzLCCI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick sanity check\n",
        "print(\"=== Dataset Summary ===\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"\\nAI Decision distribution:\\n{df['AI_decision'].value_counts()}\")\n",
        "print(f\"\\nFinal Decision distribution:\\n{df['final_decision'].value_counts()}\")\n",
        "print(f\"\\nApproval rate by country (final_decision):\")\n",
        "print(df.groupby(\"country_of_origin\")[\"final_decision\"]\n",
        "      .apply(lambda x: (x == \"approve\").mean())\n",
        "      .round(2))\n",
        "print(f\"\\nAppeals filed: {df['appealed'].sum()}\")\n",
        "print(f\"Appeals overturned: {(df['appeal_outcome'] == 'overturned').sum()}\")\n",
        "print(f\"\\nBias flag distribution:\\n{df['bias_flag'].value_counts()}\")\n",
        "print(f\"\\nTrauma rate: {df['reported_trauma'].mean():.1%}\")\n",
        "print(f\"\\nCases where trauma present but credibility < 0.5: {((df['reported_trauma']) & (df['credibility_score'] < 0.5)).sum()}\")\n",
        "\n",
        "df.to_csv(\"synthetic_RSD_dataset.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLeRCn_rLG29",
        "outputId": "ef210d26-b45e-48ae-8a3c-e64eb607e3d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Dataset Summary ===\n",
            "Shape: (500, 25)\n",
            "\n",
            "AI Decision distribution:\n",
            "AI_decision\n",
            "approve    270\n",
            "deny       230\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Final Decision distribution:\n",
            "final_decision\n",
            "approve    269\n",
            "deny       231\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Approval rate by country (final_decision):\n",
            "country_of_origin\n",
            "Afghanistan    0.48\n",
            "Eritrea        0.49\n",
            "Iraq           0.57\n",
            "Myanmar        0.50\n",
            "Somalia        0.54\n",
            "Sudan          0.56\n",
            "Syria          0.52\n",
            "Venezuela      0.63\n",
            "Name: final_decision, dtype: float64\n",
            "\n",
            "Appeals filed: 58\n",
            "Appeals overturned: 25\n",
            "\n",
            "Bias flag distribution:\n",
            "bias_flag\n",
            "none        373\n",
            "moderate     87\n",
            "severe       40\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Trauma rate: 55.2%\n",
            "\n",
            "Cases where trauma present but credibility < 0.5: 88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "wMRvDDHgLJ49",
        "outputId": "babbc7c8-a9ae-413f-c9ac-84b788cf56d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id country_of_origin  gender  age education_level language_proficiency  \\\n",
              "0   1              Iraq    Male   23        Tertiary         Intermediate   \n",
              "1   2           Myanmar    Male   23       Secondary               Fluent   \n",
              "2   3           Eritrea  Female   20       Secondary                Basic   \n",
              "3   4              Iraq    Male   24       Secondary                Basic   \n",
              "4   5             Sudan    Male   25         Primary             Advanced   \n",
              "5   6           Somalia  Female   59         Primary         Intermediate   \n",
              "6   7           Eritrea  Female   32         Primary                Basic   \n",
              "7   8           Eritrea  Female   64         Primary                Basic   \n",
              "8   9              Iraq  Female   46       Secondary                Basic   \n",
              "9  10       Afghanistan    Male   50         Primary             Advanced   \n",
              "\n",
              "   family_size  prior_camp_years persecution_ground persecution_type  ...  \\\n",
              "0            3                 3           religion   discrimination  ...   \n",
              "1            5                 9  political_opinion         violence  ...   \n",
              "2            3                 5       social_group          threats  ...   \n",
              "3            3                 9  political_opinion   discrimination  ...   \n",
              "4            4                 2  political_opinion          threats  ...   \n",
              "5            2                 1           religion         violence  ...   \n",
              "6            4                 5        nationality   discrimination  ...   \n",
              "7            4                 4       social_group        detention  ...   \n",
              "8            1                 9           religion         violence  ...   \n",
              "9            4                 4  political_opinion  sexual_violence  ...   \n",
              "\n",
              "   risk_score  risk_score_uncapped  AI_decision  human_reviewed  \\\n",
              "0    0.709255             0.709255         deny           False   \n",
              "1    0.765664             0.765664      approve           False   \n",
              "2    0.861194             0.861194      approve           False   \n",
              "3    0.619158             0.619158      approve           False   \n",
              "4    0.774955             0.774955      approve           False   \n",
              "5    0.875386             0.875386      approve           False   \n",
              "6    0.721481             0.721481         deny            True   \n",
              "7    0.789359             0.789359         deny           False   \n",
              "8    0.871403             0.871403      approve           False   \n",
              "9    1.000000             1.003554      approve           False   \n",
              "\n",
              "   human_override  final_decision  processing_time_days appealed  \\\n",
              "0           False            deny                   109    False   \n",
              "1           False         approve                    85    False   \n",
              "2           False         approve                    73    False   \n",
              "3           False         approve                    86    False   \n",
              "4           False         approve                    35    False   \n",
              "5           False         approve                    61    False   \n",
              "6            True         approve                   144    False   \n",
              "7           False            deny                    47    False   \n",
              "8           False         approve                    97    False   \n",
              "9           False         approve                   102    False   \n",
              "\n",
              "   appeal_outcome  bias_flag  \n",
              "0             N/A   moderate  \n",
              "1             N/A       none  \n",
              "2             N/A       none  \n",
              "3             N/A       none  \n",
              "4             N/A       none  \n",
              "5             N/A   moderate  \n",
              "6             N/A       none  \n",
              "7             N/A     severe  \n",
              "8             N/A       none  \n",
              "9             N/A       none  \n",
              "\n",
              "[10 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c922a072-2aec-463f-906b-5ab5cbbff11a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>country_of_origin</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>education_level</th>\n",
              "      <th>language_proficiency</th>\n",
              "      <th>family_size</th>\n",
              "      <th>prior_camp_years</th>\n",
              "      <th>persecution_ground</th>\n",
              "      <th>persecution_type</th>\n",
              "      <th>...</th>\n",
              "      <th>risk_score</th>\n",
              "      <th>risk_score_uncapped</th>\n",
              "      <th>AI_decision</th>\n",
              "      <th>human_reviewed</th>\n",
              "      <th>human_override</th>\n",
              "      <th>final_decision</th>\n",
              "      <th>processing_time_days</th>\n",
              "      <th>appealed</th>\n",
              "      <th>appeal_outcome</th>\n",
              "      <th>bias_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>Male</td>\n",
              "      <td>23</td>\n",
              "      <td>Tertiary</td>\n",
              "      <td>Intermediate</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>religion</td>\n",
              "      <td>discrimination</td>\n",
              "      <td>...</td>\n",
              "      <td>0.709255</td>\n",
              "      <td>0.709255</td>\n",
              "      <td>deny</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>deny</td>\n",
              "      <td>109</td>\n",
              "      <td>False</td>\n",
              "      <td>N/A</td>\n",
              "      <td>moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Myanmar</td>\n",
              "      <td>Male</td>\n",
              "      <td>23</td>\n",
              "      <td>Secondary</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>political_opinion</td>\n",
              "      <td>violence</td>\n",
              "      <td>...</td>\n",
              "      <td>0.765664</td>\n",
              "      <td>0.765664</td>\n",
              "      <td>approve</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>approve</td>\n",
              "      <td>85</td>\n",
              "      <td>False</td>\n",
              "      <td>N/A</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Eritrea</td>\n",
              "      <td>Female</td>\n",
              "      <td>20</td>\n",
              "      <td>Secondary</td>\n",
              "      <td>Basic</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>social_group</td>\n",
              "      <td>threats</td>\n",
              "      <td>...</td>\n",
              "      <td>0.861194</td>\n",
              "      <td>0.861194</td>\n",
              "      <td>approve</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>approve</td>\n",
              "      <td>73</td>\n",
              "      <td>False</td>\n",
              "      <td>N/A</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>Male</td>\n",
              "      <td>24</td>\n",
              "      <td>Secondary</td>\n",
              "      <td>Basic</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>political_opinion</td>\n",
              "      <td>discrimination</td>\n",
              "      <td>...</td>\n",
              "      <td>0.619158</td>\n",
              "      <td>0.619158</td>\n",
              "      <td>approve</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>approve</td>\n",
              "      <td>86</td>\n",
              "      <td>False</td>\n",
              "      <td>N/A</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Sudan</td>\n",
              "      <td>Male</td>\n",
              "      <td>25</td>\n",
              "      <td>Primary</td>\n",
              "      <td>Advanced</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>political_opinion</td>\n",
              "      <td>threats</td>\n",
              "      <td>...</td>\n",
              "      <td>0.774955</td>\n",
              "      <td>0.774955</td>\n",
              "      <td>approve</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>approve</td>\n",
              "      <td>35</td>\n",
              "      <td>False</td>\n",
              "      <td>N/A</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Somalia</td>\n",
              "      <td>Female</td>\n",
              "      <td>59</td>\n",
              "      <td>Primary</td>\n",
              "      <td>Intermediate</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>religion</td>\n",
              "      <td>violence</td>\n",
              "      <td>...</td>\n",
              "      <td>0.875386</td>\n",
              "      <td>0.875386</td>\n",
              "      <td>approve</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>approve</td>\n",
              "      <td>61</td>\n",
              "      <td>False</td>\n",
              "      <td>N/A</td>\n",
              "      <td>moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Eritrea</td>\n",
              "      <td>Female</td>\n",
              "      <td>32</td>\n",
              "      <td>Primary</td>\n",
              "      <td>Basic</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>nationality</td>\n",
              "      <td>discrimination</td>\n",
              "      <td>...</td>\n",
              "      <td>0.721481</td>\n",
              "      <td>0.721481</td>\n",
              "      <td>deny</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>approve</td>\n",
              "      <td>144</td>\n",
              "      <td>False</td>\n",
              "      <td>N/A</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Eritrea</td>\n",
              "      <td>Female</td>\n",
              "      <td>64</td>\n",
              "      <td>Primary</td>\n",
              "      <td>Basic</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>social_group</td>\n",
              "      <td>detention</td>\n",
              "      <td>...</td>\n",
              "      <td>0.789359</td>\n",
              "      <td>0.789359</td>\n",
              "      <td>deny</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>deny</td>\n",
              "      <td>47</td>\n",
              "      <td>False</td>\n",
              "      <td>N/A</td>\n",
              "      <td>severe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>Female</td>\n",
              "      <td>46</td>\n",
              "      <td>Secondary</td>\n",
              "      <td>Basic</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>religion</td>\n",
              "      <td>violence</td>\n",
              "      <td>...</td>\n",
              "      <td>0.871403</td>\n",
              "      <td>0.871403</td>\n",
              "      <td>approve</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>approve</td>\n",
              "      <td>97</td>\n",
              "      <td>False</td>\n",
              "      <td>N/A</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>Male</td>\n",
              "      <td>50</td>\n",
              "      <td>Primary</td>\n",
              "      <td>Advanced</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>political_opinion</td>\n",
              "      <td>sexual_violence</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.003554</td>\n",
              "      <td>approve</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>approve</td>\n",
              "      <td>102</td>\n",
              "      <td>False</td>\n",
              "      <td>N/A</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c922a072-2aec-463f-906b-5ab5cbbff11a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c922a072-2aec-463f-906b-5ab5cbbff11a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c922a072-2aec-463f-906b-5ab5cbbff11a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w_I-mPUUKWrG"
      }
    }
  ]
}